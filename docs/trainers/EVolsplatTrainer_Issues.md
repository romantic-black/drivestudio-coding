# EVolsplatTrainer å®ç°é—®é¢˜åˆ†æ

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†åˆ†æ EVolsplatTrainer å®ç°ä¸­å‘ç°çš„å…³é”®é—®é¢˜ï¼ŒåŒ…æ‹¬é—®é¢˜æè¿°ã€å½±å“è¯„ä¼°ã€æ ¹æœ¬åŸå› åˆ†æå’Œè§£å†³æ–¹æ¡ˆå»ºè®®ã€‚

---

## é«˜ä¼˜å…ˆçº§é—®é¢˜

### 1. é…ç½®æ–‡ä»¶é”®ä¸åŒ¹é…é—®é¢˜

**ä½ç½®**: `tools/train_evolsplat.py` (lines 75-111)

**é—®é¢˜æè¿°**:
è®­ç»ƒè„šæœ¬æœŸæœ›çš„é…ç½®é”®ä¸ç°æœ‰é…ç½®æ–‡ä»¶ä¸åŒ¹é…ï¼š

- è„šæœ¬æœŸæœ›ï¼š`cfg.data`, `cfg.multi_scene`, `cfg.data.pointcloud`, `cfg.trainer`
- ç°æœ‰é…ç½®ï¼š`multi_scene.yaml` å’Œ `trainer_config.yaml` ä¸æä¾›è¿™äº›é”®

**é”™è¯¯ç¤ºä¾‹**:

```python
# train_evolsplat.py line 75-111
dataset = MultiSceneDataset(
    data_cfg=cfg.data,  # âŒ AttributeError: 'OmegaConf' object has no attribute 'data'
    train_scene_ids=cfg.data.train_scene_ids,  # âŒ åŒä¸Š
    ...
)
```

**å½±å“**:

- **ä¸¥é‡æ€§**: ğŸ”´ **High** - è®­ç»ƒæ— æ³•å¯åŠ¨
- ä½¿ç”¨ä»»ä¸€é…ç½®æ–‡ä»¶ä½œä¸º `--config_file` éƒ½ä¼šåœ¨è®­ç»ƒå¼€å§‹å‰æŠ›å‡º `AttributeError`
- é˜»æ­¢æ‰€æœ‰è®­ç»ƒå’Œæµ‹è¯•

**æ ¹æœ¬åŸå› **:

1. é…ç½®æ–‡ä»¶ç»“æ„ä¸è„šæœ¬æœŸæœ›ä¸ä¸€è‡´
2. `multi_scene.yaml` åŒ…å« `data`ï¼ˆå…¶ä¸­åŒ…å« `pointcloud`ï¼‰å’Œ `multi_scene`ï¼Œä½†ç¼ºå°‘ `trainer`
3. `trainer_config.yaml` åªåŒ…å« `trainer` ç›¸å…³é…ç½®ï¼Œç¼ºå°‘ `data`ã€`multi_scene` å’Œ `data.pointcloud`

**è§£å†³æ–¹æ¡ˆ**:

å‚è€ƒomnire.yamlï¼Œdatasetä¸­è®¾ç½®å¯¹åº”é…ç½®æ–‡ä»¶è·¯å¾„å³å¯

---

### 2. ç‰¹å¾ç»´åº¦ä¸åŒ¹é…é—®é¢˜

**ä½ç½®**: `models/trainers/evolsplat.py` (lines 538-549)

**é—®é¢˜æè¿°**:
`sample_within_window` è¿”å›çš„ `sampled_feat` å’Œ `vis_map` çš„æœ€åä¸€ä¸ªç»´åº¦æ˜¯ 4ï¼Œä½†ä»£ç å°è¯•å°†å…¶ reshape åˆ° `self.feature_dim_in`ï¼ˆé»˜è®¤ 144ï¼‰ï¼Œå¯¼è‡´ç»´åº¦ä¸åŒ¹é…ã€‚

**é”™è¯¯ä»£ç **:

```python
# evolsplat.py lines 538-549
sampled_feat, valid_mask, vis_map = self.projector.sample_within_window(...)
# sampled_feat: [N, num_views, 4] (å‡è®¾)
# vis_map: [N, num_views, 4] (å‡è®¾)

sampled_feat = torch.concat([sampled_feat, vis_map], dim=-1).reshape(-1, self.feature_dim_in)
# âŒ å¦‚æœ sampled_feat å’Œ vis_map çš„æœ€åä¸€ä¸ªç»´åº¦æ˜¯ 4ï¼Œconcat åæ˜¯ 8
# âŒ reshape åˆ° feature_dim_in (144) ä¼šå¤±è´¥
```

**å½±å“**:

- **ä¸¥é‡æ€§**: ğŸ”´ **High** - è®­ç»ƒä¼šåœ¨ç‰¹å¾æå–é˜¶æ®µå´©æºƒ
- æ‰€æœ‰ä½¿ç”¨ `extract_shared_features` çš„æ“ä½œéƒ½ä¼šå¤±è´¥
- é˜»æ­¢è®­ç»ƒå’Œè¯„ä¼°

**æ ¹æœ¬åŸå› **:

1. `feature_dim_in` çš„è®¡ç®—åŸºäºå‡è®¾çš„ç»´åº¦ï¼š`4 * num_neighbours * (2 * local_radius + 1) ** 2`
2. å®é™… `sample_within_window` è¿”å›çš„ç‰¹å¾ç»´åº¦å¯èƒ½ä¸åŒ
3. ä»£ç æ²¡æœ‰éªŒè¯æˆ–é€‚é…å®é™…è¿”å›çš„ç»´åº¦

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ¡ˆ B: ä½¿ç”¨æ­£ç¡®çš„çª—å£å¸ƒå±€

ä¼˜å…ˆå‚è€ƒ EVolsplat çš„åŸå§‹å®ç°ï¼Œç¡®ä¿ç‰¹å¾ç»´åº¦è®¡ç®—æ­£ç¡®ï¼š

```python
# æ ¹æ® EVolsplat åŸå§‹å®ç°
# sampled_feat: [N, num_views, C] where C depends on window size
# vis_map: [N, num_views, 4] (visibility map)

# æ­£ç¡®çš„å¤„ç†æ–¹å¼
sampled_feat_flat = sampled_feat.reshape(-1, sampled_feat.shape[-1])  # [N*num_views, C]
vis_map_flat = vis_map.reshape(-1, vis_map.shape[-1])  # [N*num_views, 4]

# å¯¹äºæ¯ä¸ªç‚¹ï¼Œéœ€è¦é€‰æ‹©æœ‰æ•ˆçš„è§†å›¾ç‰¹å¾
# è¿™éœ€è¦æ ¹æ® valid_mask å’Œ projection_mask æ¥å¤„ç†


```

```

```

---

### 2.1 MLP ç»´åº¦ä¸åŒ¹é…é—®é¢˜ï¼ˆé—®é¢˜2çš„å»¶ä¼¸ï¼‰âœ… å·²ä¿®å¤

**ä½ç½®**: `models/trainers/evolsplat.py` (lines 549-576, 668-671)

**é—®é¢˜æè¿°**:

`sample_within_window` è¿”å›æ‰€æœ‰æºè§†å›¾çš„ç‰¹å¾ï¼ˆä¾‹å¦‚é»˜è®¤é…ç½®ä¸‹æ˜¯9ä¸ªè§†å›¾ï¼‰ï¼Œæ‰€ä»¥ `sampled_feat` è¢« reshape åˆ° `4 * num_views * (2R+1)^2` (=324ï¼Œå½“ num_views=9, R=1 æ—¶)ã€‚ä½†æ˜¯ `gaussion_decoder` æ˜¯ç”¨ `feature_dim_in` æ„å»ºçš„ï¼Œè€Œ `feature_dim_in` æ˜¯ä» `num_neighbour_select`ï¼ˆé»˜è®¤4ï¼‰æ¨å¯¼å‡ºæ¥çš„ï¼ˆâ†’ 144è¾“å…¥ï¼‰ã€‚åœ¨è¿è¡Œæ—¶æ›´æ–° `self.feature_dim_in` ä¸ä¼šè°ƒæ•´ MLP çš„å¤§å°ï¼Œæ‰€ä»¥å½“è§†å›¾æ•°>4æ—¶ï¼Œç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­ä¼šæŠ›å‡ºç»´åº¦ä¸åŒ¹é…é”™è¯¯ã€‚

**ä¿®å¤çŠ¶æ€**: âœ… **å·²é€šè¿‡æ–¹æ¡ˆCä¿®å¤**

**ä¿®å¤å†…å®¹**:
- âœ… åˆ é™¤äº† `num_neighbour_select` é…ç½®é¡¹ï¼ˆä» `trainer_config.yaml` ä¸­ç§»é™¤ï¼‰
- âœ… åœ¨ `_init_networks` ä¸­ç›´æ¥ä» `self.dataset` è¯»å–å®é™…çš„æºè§†å›¾æ•°é‡ï¼š
  - `num_source_keyframes = self.dataset.num_source_keyframes`
  - `num_cams` ä»ç¬¬ä¸€ä¸ªåœºæ™¯çš„ `scene_data['num_cams']` è·å–ï¼Œæˆ–ä»é…ç½®ä¸­è·å–
  - `num_source_views = num_source_keyframes Ã— num_cams`
- âœ… `gaussion_decoder` ç°åœ¨ä½¿ç”¨æ­£ç¡®çš„ `feature_dim_in` æ„å»ºï¼ˆåŸºäºå®é™…çš„ `num_source_views`ï¼‰
- âœ… åœ¨ `extract_shared_features` ä¸­æ·»åŠ äº†ç»´åº¦éªŒè¯ï¼Œç¡®ä¿å®é™…è§†å›¾æ•°é‡ä¸é¢„æœŸåŒ¹é…
- âœ… æ›´æ–°äº†æ‰€æœ‰æ³¨é‡Šï¼Œåˆ é™¤äº†å¯¹ `num_neibours` çš„å¼•ç”¨
- âœ… æ·»åŠ äº† `num_target_views` çš„è®¡ç®—ï¼ˆç”¨äºå‚è€ƒï¼‰

**é”™è¯¯ä»£ç **:

```python
# evolsplat.py lines 549-576
# Get actual number of views from sampled_feat
num_views = sampled_feat.shape[1]  # ä¾‹å¦‚ 9 ä¸ªè§†å›¾

# Calculate actual feature dimension
actual_feature_dim_in = 4 * num_views * window_size  # ä¾‹å¦‚ 324

# Update feature_dim_in if it doesn't match
if actual_feature_dim_in != self.feature_dim_in:
    self.feature_dim_in = actual_feature_dim_in  # âŒ åªæ›´æ–°äº†å±æ€§ï¼Œæ²¡æœ‰é‡å»º MLP
    # Note: This might require reinitializing gaussion_decoder, but for now we'll proceed
    # âŒ å®é™…ä¸Šä¼šå¯¼è‡´ç»´åº¦ä¸åŒ¹é…é”™è¯¯

# evolsplat.py lines 668-671
input_feature = torch.cat([sampled_color, ob_dist, ob_view], dim=-1).squeeze(dim=1)
# sampled_color: [N, 324] (å¦‚æœ num_views=9)
# input_feature: [N, 324+4] = [N, 328]

sh = self.gaussion_decoder(input_feature)  # âŒ RuntimeError: æœŸæœ›è¾“å…¥ç»´åº¦ 144+4=148ï¼Œå®é™…å¾—åˆ° 328
```

**å½±å“**:

- **ä¸¥é‡æ€§**: ğŸ”´ **High** - è®­ç»ƒä¼šåœ¨ç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­æ—¶å´©æºƒ
- å½“æºè§†å›¾æ•°é‡ > `num_neighbour_select` æ—¶å¿…ç„¶å¤±è´¥
- é»˜è®¤é…ç½®ï¼ˆ9ä¸ªè§†å›¾ï¼Œnum_neighbour_select=4ï¼‰æ— æ³•å·¥ä½œ

**æ ¹æœ¬åŸå› **:

1. `gaussion_decoder` åœ¨åˆå§‹åŒ–æ—¶ä½¿ç”¨ `feature_dim_in`ï¼ˆåŸºäº `num_neighbour_select`ï¼‰æ„å»º
2. å®é™…è¿è¡Œæ—¶ï¼Œ`sample_within_window` è¿”å›æ‰€æœ‰æºè§†å›¾çš„ç‰¹å¾
3. è¿è¡Œæ—¶æ›´æ–° `self.feature_dim_in` ä¸ä¼šé‡å»º MLPï¼ŒMLP çš„è¾“å…¥ç»´åº¦ä»ç„¶æ˜¯åˆå§‹åŒ–æ—¶çš„å€¼
4. å½“å®é™…ç‰¹å¾ç»´åº¦ > MLP è¾“å…¥ç»´åº¦æ—¶ï¼Œå‰å‘ä¼ æ’­ä¼šå¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ¡ˆ A: é™åˆ¶è§†å›¾æ•°é‡åˆ° `num_neighbour_select`ï¼ˆæ¨èï¼‰

åœ¨ reshape ä¹‹å‰ï¼Œåªé€‰æ‹© `num_neighbour_select` ä¸ªè§†å›¾ï¼š

```python
# evolsplat.py extract_shared_features æ–¹æ³•ä¸­
sampled_feat, valid_mask, vis_map = self.projector.sample_within_window(...)
# sampled_feat: [N, num_views, (2R+1)^2, 3]
# valid_mask: [N, num_views, (2R+1)^2]
# vis_map: [N, num_views, (2R+1)^2, 1]

# Limit to num_neighbour_select views
num_views = sampled_feat.shape[1]
if num_views > self.num_neighbours:
    # Select first num_neighbours views (or use a smarter selection strategy)
    sampled_feat = sampled_feat[:, :self.num_neighbours, :, :]  # [N, num_neighbours, (2R+1)^2, 3]
    valid_mask = valid_mask[:, :self.num_neighbours, :]  # [N, num_neighbours, (2R+1)^2]
    vis_map = vis_map[:, :self.num_neighbours, :, :]  # [N, num_neighbours, (2R+1)^2, 1]
    logger.info(f"Limited views from {num_views} to {self.num_neighbours} to match MLP input dimension")

# Now reshape with correct dimension
sampled_feat = torch.concat([sampled_feat, vis_map], dim=-1)  # [N, num_neighbours, (2R+1)^2, 4]
sampled_feat = sampled_feat.reshape(sampled_feat.shape[0], self.feature_dim_in)  # [N, feature_dim_in]
```

**ä¼˜ç‚¹**: 
- ç®€å•ç›´æ¥ï¼Œä¸éœ€è¦é‡å»º MLP
- ä¸ EVolsplat åŸå§‹è®¾è®¡ä¸€è‡´ï¼ˆ`num_neighbour_select` å°±æ˜¯ç”¨æ¥é™åˆ¶è§†å›¾æ•°é‡çš„ï¼‰

**ç¼ºç‚¹**: 
- ä¸¢å¼ƒäº†ä¸€äº›è§†å›¾çš„ä¿¡æ¯

#### æ–¹æ¡ˆ B: åŠ¨æ€é‡å»º MLPï¼ˆå¤æ‚ä½†çµæ´»ï¼‰

æ£€æµ‹åˆ°ç»´åº¦ä¸åŒ¹é…æ—¶ï¼Œé‡å»º `gaussion_decoder`ï¼š

```python
# evolsplat.py extract_shared_features æ–¹æ³•ä¸­
actual_feature_dim_in = 4 * num_views * window_size

if actual_feature_dim_in != self.feature_dim_in:
    logger.warning(
        f"Feature dimension mismatch: expected {self.feature_dim_in}, "
        f"got {actual_feature_dim_in}. Rebuilding gaussion_decoder."
    )
    
    # Rebuild gaussion_decoder with correct input dimension
    self.feature_dim_in = actual_feature_dim_in
    self.gaussion_decoder = MLP(
        in_dim=self.feature_dim_in + 4,
        num_layers=3,
        layer_width=128,
        out_dim=self.feature_dim_out,
        activation=nn.ReLU(),
        out_activation=None,
        implementation="torch",
    ).to(self.device)
    
    # Update optimizer to include new parameters
    # (Need to remove old parameters and add new ones)
    # This is complex and may require optimizer state reset
```

**ä¼˜ç‚¹**: 
- ä½¿ç”¨æ‰€æœ‰è§†å›¾çš„ä¿¡æ¯
- æ›´çµæ´»

**ç¼ºç‚¹**: 
- å®ç°å¤æ‚ï¼Œéœ€è¦æ›´æ–°ä¼˜åŒ–å™¨
- å¯èƒ½å½±å“è®­ç»ƒç¨³å®šæ€§ï¼ˆMLP æƒé‡é‡æ–°åˆå§‹åŒ–ï¼‰

#### æ–¹æ¡ˆ C: åˆ é™¤é…ç½®é¡¹ï¼Œä» dataset è¯»å–ï¼ˆâœ… å·²é‡‡ç”¨ï¼‰

**å®ç°æ–¹å¼**:
1. åˆ é™¤ `num_neighbour_select` é…ç½®é¡¹
2. åœ¨åˆå§‹åŒ–æ—¶ç›´æ¥ä» `self.dataset` è¯»å–å®é™…çš„æºè§†å›¾æ•°é‡
3. ä½¿ç”¨å®é™…æ•°é‡æ„å»º MLPï¼Œç¡®ä¿ç»´åº¦åŒ¹é…

**å·²å®ç°çš„ä»£ç **:
```python
# evolsplat.py _init_networks ä¸­
# Calculate number of source views from dataset configuration
num_source_keyframes = self.dataset.num_source_keyframes

# Get number of cameras from dataset
num_cams = None
if hasattr(self.dataset, 'train_scene_ids') and len(self.dataset.train_scene_ids) > 0:
    try:
        scene_data = self.dataset._ensure_scene_loaded(self.dataset.train_scene_ids[0])
        if scene_data is not None and 'num_cams' in scene_data:
            num_cams = scene_data['num_cams']
    except Exception as e:
        logger.debug(f"Could not get num_cams from scene data: {e}")

# Fallback: get from config if available
if num_cams is None:
    if hasattr(self.config, 'data') and hasattr(self.config.data, 'pixel_source'):
        cameras = self.config.data.pixel_source.get('cameras', [0, 1, 2])
        num_cams = len(cameras) if isinstance(cameras, list) else 1
    else:
        num_cams = 3  # Default fallback

# Number of source views = num_source_keyframes * num_cams
self.num_source_views = num_source_keyframes * num_cams

# Use actual number to calculate feature_dim_in
self.feature_dim_in = 4 * self.num_source_views * (2 * self.local_radius + 1) ** 2

# Build gaussion_decoder with correct input dimension
self.gaussion_decoder = MLP(
    in_dim=self.feature_dim_in + 4,  # ç¡®ä¿ç»´åº¦æ­£ç¡®
    ...
)
```

**ä¼˜ç‚¹**: 
- âœ… å®Œå…¨æ¶ˆé™¤é…ç½®ä¸ä¸€è‡´çš„é—®é¢˜
- âœ… è‡ªåŠ¨é€‚é…ä¸åŒçš„æ•°æ®é›†é…ç½®
- âœ… åœ¨åˆå§‹åŒ–æ—¶å°±ç¡®ä¿ç»´åº¦æ­£ç¡®ï¼Œé¿å…è¿è¡Œæ—¶é”™è¯¯
- âœ… ä»£ç æ›´ç®€æ´ï¼Œä¸éœ€è¦ç»´æŠ¤é¢å¤–çš„é…ç½®é¡¹

**ç¼ºç‚¹**: 
- æ— ï¼ˆè¿™æ˜¯æœ€ä½³å®è·µï¼‰

---

### 3. å…±äº«ç‰¹å¾å›¾åœ¨å¤šæ¬¡åå‘ä¼ æ’­ä¸­çš„é—®é¢˜

**ä½ç½®**: `models/trainers/evolsplat.py` (lines 847-876)

**é—®é¢˜æè¿°**:
å…±äº«ç‰¹å¾åªè®¡ç®—ä¸€æ¬¡ï¼Œç„¶ååœ¨å¤šä¸ª target view ä¸Šé‡å¤ä½¿ç”¨ï¼Œä½†æ¯æ¬¡ `loss.backward()` è°ƒç”¨éƒ½ä¼šé‡Šæ”¾è®¡ç®—å›¾ã€‚å½“æœ‰å¤šä¸ª target viewï¼ˆé»˜è®¤ 6 ä¸ªï¼‰æ—¶ï¼Œç¬¬äºŒæ¬¡ `backward()` ä¼šå¤±è´¥ï¼Œå› ä¸ºè®¡ç®—å›¾å·²è¢«é‡Šæ”¾ã€‚

**é”™è¯¯ä»£ç **:

```python
# evolsplat.py lines 847-876
# 1. æå–å…±äº«ç‰¹å¾ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
shared_state = self.extract_shared_features(batch, node, offset)

# 2. å¯¹æ¯ä¸ª target view å¾ªç¯
for target_idx in range(num_target_views):  # é»˜è®¤ 6 ä¸ª
    outputs = self.render_for_target_view(target_view, shared_state, node, offset)
    loss = self.compute_loss(outputs, target_view['image'])
    loss.backward()  # âŒ ç¬¬ä¸€æ¬¡ backward åï¼Œè®¡ç®—å›¾è¢«é‡Šæ”¾
                      # âŒ ç¬¬äºŒæ¬¡ backward ä¼šå¤±è´¥ï¼Œå› ä¸º shared_state çš„è®¡ç®—å›¾å·²ä¸å­˜åœ¨
```

**å½±å“**:

- **ä¸¥é‡æ€§**: ğŸ”´ **High** - è®­ç»ƒä¼šåœ¨ç¬¬äºŒä¸ª target view çš„åå‘ä¼ æ’­æ—¶å´©æºƒ
- é»˜è®¤é…ç½®ï¼ˆ6 ä¸ª target viewsï¼‰æ— æ³•å·¥ä½œ
- åªæœ‰å•ä¸ª target view æ—¶æ‰èƒ½è®­ç»ƒï¼ˆä½†è¿™ä¸æ˜¯é¢„æœŸè¡Œä¸ºï¼‰

**æ ¹æœ¬åŸå› **:

1. å…±äº«ç‰¹å¾çš„è®¡ç®—å›¾åœ¨ç¬¬ä¸€æ¬¡ `backward()` åè¢«é‡Šæ”¾
2. åç»­ target view ä½¿ç”¨ç›¸åŒçš„ `shared_state`ï¼Œä½†è®¡ç®—å›¾å·²ä¸å­˜åœ¨
3. è®¾è®¡æ„å›¾æ˜¯å…±äº«ç‰¹å¾ï¼Œä½†å®ç°æ²¡æœ‰è€ƒè™‘è®¡ç®—å›¾çš„ä¿ç•™

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ¡ˆ C: åˆ†ç¦»å…±äº«ç‰¹å¾å’Œå¯å¾®åˆ†ç‰¹å¾ï¼ˆæœ€ä½³ä½†å¤æ‚ï¼‰

å°†å…±äº«ç‰¹å¾åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š

1. **ä¸å¯å¾®åˆ†éƒ¨åˆ†**ï¼ˆ3D ä½“ç§¯ã€é‡‡æ ·ç‰¹å¾ç­‰ï¼‰- åªè®¡ç®—ä¸€æ¬¡ï¼Œdetach
2. **å¯å¾®åˆ†éƒ¨åˆ†**ï¼ˆæ¯ä¸ª view ç‰¹å®šçš„ç‰¹å¾ï¼‰- æ¯æ¬¡é‡æ–°è®¡ç®—

```python
# æå–å…±äº«ç‰¹å¾ï¼ˆdetach ä¸å¯å¾®åˆ†éƒ¨åˆ†ï¼‰
shared_state = self.extract_shared_features(batch, node, offset)
shared_state_detached = {
    k: v.detach() if isinstance(v, torch.Tensor) else v
    for k, v in shared_state.items()
}

# å¯¹æ¯ä¸ª target viewï¼Œé‡æ–°è®¡ç®—å¯å¾®åˆ†éƒ¨åˆ†
for target_idx in range(num_target_views):
    # é‡æ–°è®¡ç®—å¯å¾®åˆ†ç‰¹å¾ï¼ˆåŸºäº detach çš„å…±äº«ç‰¹å¾ï¼‰
    outputs = self.render_for_target_view(target_view, shared_state_detached, node, offset)
    loss = self.compute_loss(outputs, target_view['image'])
    loss.backward()  # ä¸éœ€è¦ retain_graph
```

---

### 4. è¯„ä¼°æ‰¹æ¬¡é‡‡æ ·æ–¹æ³•å‚æ•°é”™è¯¯

**ä½ç½®**: `tools/train_evolsplat.py` (lines 168-181)

**é—®é¢˜æè¿°**:
è¯„ä¼°ä»£ç è°ƒç”¨ `dataset.sample_random_batch(eval=True)`ï¼Œä½† `MultiSceneDataset.sample_random_batch()` æ–¹æ³•ä¸æ¥å— `eval` å‚æ•°ã€‚

**é”™è¯¯ä»£ç **:

```python
# train_evolsplat.py lines 168-181
eval_batch = dataset.sample_random_batch(eval=True)  # âŒ TypeError
```

**å½±å“**:

- **ä¸¥é‡æ€§**: ğŸ”´ **High** - è¯„ä¼°æ— æ³•è¿è¡Œ
- è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¯„ä¼°ä¼šå¤±è´¥
- æ— æ³•è·å–è¯„ä¼°æŒ‡æ ‡

**æ ¹æœ¬åŸå› **:

1. `sample_random_batch()` æ–¹æ³•ç­¾åä¸åŒ…å« `eval` å‚æ•°
2. éœ€è¦ä»è¯„ä¼°åœºæ™¯ä¸­é‡‡æ ·ï¼Œä½†å½“å‰æ–¹æ³•åªä»è®­ç»ƒåœºæ™¯é‡‡æ ·

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ¡ˆ A: ä¿®æ”¹ `sample_random_batch` æ–¹æ³•æ”¯æŒ eval å‚æ•°

åœ¨ `MultiSceneDataset` ä¸­æ·»åŠ  `eval` å‚æ•°ï¼š

```python
# datasets/multi_scene_dataset.py
def sample_random_batch(self, eval: bool = False) -> Dict:
    """
    Randomly sample a training batch.
  
    Args:
        eval: If True, sample from eval scenes; otherwise from train scenes
    """
    if eval:
        scene_ids = self.eval_scene_ids
    else:
        scene_ids = self.train_scene_ids
  
    # ... ä»ç›¸åº”çš„åœºæ™¯ä¸­é‡‡æ ·
```

---

## ä¸­ä¼˜å…ˆçº§é—®é¢˜

### 5. æ£€æŸ¥ç‚¹åŠ è½½æ—¶èŠ‚ç‚¹çŠ¶æ€æœªæ¢å¤

**ä½ç½®**: `models/trainers/evolsplat.py` (lines 1016-1029)

**é—®é¢˜æè¿°**:
æ£€æŸ¥ç‚¹åŠ è½½æ—¶ï¼ŒèŠ‚ç‚¹çŠ¶æ€çš„æ¢å¤æ˜¯å­˜æ ¹å®ç°ï¼ˆåªæœ‰ `pass`ï¼‰ï¼Œå¯¼è‡´æ¢å¤è®­ç»ƒæ—¶èŠ‚ç‚¹å’Œ offset çŠ¶æ€æœªæ¢å¤ã€‚

**é—®é¢˜ä»£ç **:

```python
# evolsplat.py lines 1016-1029
if "nodes_state_dict" in checkpoint:
    nodes_state_dict = checkpoint["nodes_state_dict"]
    for key_str, node_state in nodes_state_dict.items():
        # Parse key: "scene_{scene_id}_segment_{segment_id}"
        parts = key_str.split("_")
        scene_id = int(parts[1])
        segment_id = int(parts[3])
        segment_key = (scene_id, segment_id)
  
        # Recreate node (simplified - may need full initialization)
        # For now, just store the state
        # TODO: Properly restore node if needed
        pass  # âŒ èŠ‚ç‚¹çŠ¶æ€æœªæ¢å¤
```

**å½±å“**:

- **ä¸¥é‡æ€§**: ğŸŸ¡ **Medium** - æ¢å¤è®­ç»ƒä¼šå¤±è´¥æˆ–ä»ç©ºèŠ‚ç‚¹å¼€å§‹
- æ¢å¤è®­ç»ƒæ—¶ï¼Œæ‰€æœ‰èŠ‚ç‚¹éœ€è¦é‡æ–°åˆå§‹åŒ–
- è®­ç»ƒè¿›åº¦ä¸¢å¤±ï¼ˆèŠ‚ç‚¹çŠ¶æ€æ˜¯è®­ç»ƒçš„ä¸€éƒ¨åˆ†ï¼‰

**æ ¹æœ¬åŸå› **:

1. èŠ‚ç‚¹æ¢å¤éœ€è¦å®Œæ•´çš„ VanillaGaussians åˆå§‹åŒ–æµç¨‹
2. èŠ‚ç‚¹çŠ¶æ€åŒ…å«å¤šä¸ªå±æ€§ï¼ˆmeans, scales, features_dc, features_rest, opacities, quatsï¼‰
3. å®ç°æ—¶æ ‡è®°ä¸º TODOï¼Œä½†æœªå®Œæˆ

**è§£å†³æ–¹æ¡ˆ**:

å‚è€ƒVanillaGaussianså’ŒBasicTrainerçš„load_state_dictä»¥åŠDrivestudioçš„checkpointåŠ è½½ï¼Œä¿å­˜æ–¹æ³•

---

### 6. ç†µæŸå¤±æœªåŠ å…¥ä¸»æŸå¤±

**ä½ç½®**: `models/trainers/evolsplat.py` (lines 750-761)

**é—®é¢˜æè¿°**:
ç†µæŸå¤±è¢«è®¡ç®—ä½†ä»æœªåŠ å…¥ `main_loss`ï¼Œå¯¼è‡´é…ç½®çš„æƒé‡è¢«å¿½ç•¥ï¼Œæ­£åˆ™åŒ–æ•ˆæœä¸ç”Ÿæ•ˆã€‚

**é—®é¢˜ä»£ç **:

```python
# evolsplat.py lines 750-761
entropy_loss = entropy_loss_weight * (
    -accumulation * torch.log(accumulation + 1e-10)
    - (1 - accumulation) * torch.log(1 - accumulation + 1e-10)
).mean()

# Total loss
main_loss = (1 - ssim_lambda) * l1_loss + ssim_lambda * ssim_loss
# âŒ entropy_loss æœªåŠ å…¥ main_loss

loss_dict = {
    "main_loss": main_loss,
    "l1_loss": l1_loss,
    "ssim_loss": ssim_loss,
    "entropy_loss": entropy_loss,  # åªè®°å½•ï¼Œä¸å‚ä¸ä¼˜åŒ–
}
```

**å½±å“**:

- **ä¸¥é‡æ€§**: ğŸŸ¡ **Medium** - ç†µæ­£åˆ™åŒ–ä¸ç”Ÿæ•ˆ
- é…ç½®çš„ `entropy_loss` æƒé‡è¢«å¿½ç•¥
- å¯èƒ½å½±å“è®­ç»ƒè´¨é‡ï¼ˆå¦‚æœç†µæ­£åˆ™åŒ–æ˜¯è®¾è®¡çš„ä¸€éƒ¨åˆ†ï¼‰

**æ ¹æœ¬åŸå› **:

1. ç†µæŸå¤±è¢«è®¡ç®—å’Œè®°å½•ï¼Œä½†æœªåŠ å…¥ä¼˜åŒ–ç›®æ ‡
2. å¯èƒ½æ˜¯å®ç°é—æ¼

**è§£å†³æ–¹æ¡ˆ**:

å°†ç†µæŸå¤±åŠ å…¥ä¸»æŸå¤±ï¼š

```python
# evolsplat.py compute_loss æ–¹æ³•ä¸­
# è®¡ç®—ç†µæŸå¤±
entropy_loss_weight = self.config.loss.get("entropy_loss", 0.1)
if self.step % 10 == 0:
    entropy_loss = entropy_loss_weight * (
        -accumulation * torch.log(accumulation + 1e-10)
        - (1 - accumulation) * torch.log(1 - accumulation + 1e-10)
    ).mean()
else:
    entropy_loss = torch.tensor(0.0, device=self.device)

# å°†ç†µæŸå¤±åŠ å…¥ä¸»æŸå¤±
main_loss = (1 - ssim_lambda) * l1_loss + ssim_lambda * ssim_loss + entropy_loss

loss_dict = {
    "main_loss": main_loss,
    "l1_loss": l1_loss,
    "ssim_loss": ssim_loss,
    "entropy_loss": entropy_loss,
}
```

---

## é—®é¢˜ä¼˜å…ˆçº§æ€»ç»“

| ä¼˜å…ˆçº§    | é—®é¢˜               | å½±å“             | ä¿®å¤éš¾åº¦ | çŠ¶æ€     |
| --------- | ------------------ | ---------------- | -------- | -------- |
| ğŸ”´ High   | é…ç½®æ–‡ä»¶é”®ä¸åŒ¹é…   | è®­ç»ƒæ— æ³•å¯åŠ¨     | ä½       | å¾…ä¿®å¤   |
| ğŸ”´ High   | ç‰¹å¾ç»´åº¦ä¸åŒ¹é…     | ç‰¹å¾æå–å´©æºƒ     | ä¸­       | å¾…ä¿®å¤   |
| ğŸ”´ High   | MLP ç»´åº¦ä¸åŒ¹é…      | å‰å‘ä¼ æ’­å¤±è´¥     | ä¸­       | âœ… å·²ä¿®å¤ |
| ğŸ”´ High   | å…±äº«ç‰¹å¾å›¾é—®é¢˜     | å¤šæ¬¡åå‘ä¼ æ’­å¤±è´¥ | ä¸­       | å¾…ä¿®å¤   |
| ğŸ”´ High   | è¯„ä¼°æ‰¹æ¬¡é‡‡æ ·é”™è¯¯   | è¯„ä¼°æ— æ³•è¿è¡Œ     | ä½       | å¾…ä¿®å¤   |
| ğŸŸ¡ Medium | èŠ‚ç‚¹çŠ¶æ€æœªæ¢å¤     | æ¢å¤è®­ç»ƒå¤±è´¥     | ä¸­       | å¾…ä¿®å¤   |
| ğŸŸ¡ Medium | ç†µæŸå¤±æœªåŠ å…¥ä¸»æŸå¤± | æ­£åˆ™åŒ–ä¸ç”Ÿæ•ˆ     | ä½       | å¾…ä¿®å¤   |

---

## ä¿®å¤å»ºè®®é¡ºåº

1. **ç«‹å³ä¿®å¤**ï¼ˆé˜»æ­¢è®­ç»ƒï¼‰:

   - é…ç½®æ–‡ä»¶é”®ä¸åŒ¹é…ï¼ˆé—®é¢˜ 1ï¼‰
   - è¯„ä¼°æ‰¹æ¬¡é‡‡æ ·é”™è¯¯ï¼ˆé—®é¢˜ 4ï¼‰
2. **é«˜ä¼˜å…ˆçº§ä¿®å¤**ï¼ˆè®­ç»ƒä¼šå´©æºƒï¼‰:

   - âœ… MLP ç»´åº¦ä¸åŒ¹é…ï¼ˆé—®é¢˜ 2.1ï¼‰- **å·²é€šè¿‡æ–¹æ¡ˆCä¿®å¤**
   - ç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼ˆé—®é¢˜ 2ï¼‰
   - å…±äº«ç‰¹å¾å›¾é—®é¢˜ï¼ˆé—®é¢˜ 3ï¼‰
3. **ä¸­ä¼˜å…ˆçº§ä¿®å¤**ï¼ˆåŠŸèƒ½ä¸å®Œæ•´ï¼‰:

   - èŠ‚ç‚¹çŠ¶æ€æ¢å¤ï¼ˆé—®é¢˜ 5ï¼‰
   - ç†µæŸå¤±åŠ å…¥ä¸»æŸå¤±ï¼ˆé—®é¢˜ 6ï¼‰

---

## æµ‹è¯•å»ºè®®

ä¿®å¤æ¯ä¸ªé—®é¢˜åï¼Œå»ºè®®è¿›è¡Œä»¥ä¸‹æµ‹è¯•ï¼š

1. **é…ç½®æ–‡ä»¶æµ‹è¯•**: ä½¿ç”¨åˆå¹¶åçš„é…ç½®æ–‡ä»¶è¿è¡Œè®­ç»ƒè„šæœ¬ï¼Œç¡®ä¿æ—  `AttributeError`
2. **ç‰¹å¾ç»´åº¦æµ‹è¯•**: æ‰“å° `sample_within_window` çš„å®é™…è¿”å›ç»´åº¦ï¼ŒéªŒè¯ reshape æ­£ç¡®
3. **å¤šæ¬¡åå‘ä¼ æ’­æµ‹è¯•**: ä½¿ç”¨å¤šä¸ª target views è®­ç»ƒï¼Œç¡®ä¿ä¸ä¼šåœ¨ç¬¬äºŒæ¬¡ `backward()` æ—¶å´©æºƒ
4. **è¯„ä¼°æµ‹è¯•**: è¿è¡Œè¯„ä¼°å¾ªç¯ï¼Œç¡®ä¿ `sample_random_batch(eval=True)` æ­£å¸¸å·¥ä½œ
5. **æ£€æŸ¥ç‚¹æµ‹è¯•**: ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œæ¢å¤è®­ç»ƒï¼ŒéªŒè¯èŠ‚ç‚¹çŠ¶æ€æ­£ç¡®æ¢å¤
6. **æŸå¤±æµ‹è¯•**: æ£€æŸ¥è®­ç»ƒæ—¥å¿—ï¼Œç¡®è®¤ç†µæŸå¤±è¢«åŠ å…¥ä¸»æŸå¤±å¹¶å½±å“ä¼˜åŒ–

---

## ç»“è®º

è¿™äº›é—®é¢˜éœ€è¦åœ¨è®­ç»ƒå‰ä¿®å¤ã€‚å»ºè®®æŒ‰ç…§ä¼˜å…ˆçº§é¡ºåºé€ä¸€ä¿®å¤ï¼Œå¹¶åœ¨æ¯æ¬¡ä¿®å¤åè¿›è¡Œæµ‹è¯•éªŒè¯ã€‚
