{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MultiSceneDataset 使用示例\n",
        "\n",
        "本 notebook 演示如何使用 `MultiSceneDataset` 进行多场景数据加载，支持 EVolSplat 的 feed-forward 3DGS 训练。\n",
        "\n",
        "## 主要功能\n",
        "1. 多场景管理（训练/评估场景分离）\n",
        "2. 基于关键帧的场景分段\n",
        "3. 段内随机选择 source/target 关键帧\n",
        "4. 打包成 EVolSplat 格式的批次数据\n",
        "5. **后台线程预加载**：类似 torch DataLoader 的 worker 线程，持续预加载场景，确保训练队列满\n",
        "6. **线程安全**：所有队列和缓存操作都使用锁保护，支持多线程场景加载\n",
        "7. **阻塞等待机制**：场景切换时，如果场景未加载完成，主线程阻塞等待，确保数据就绪\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from omegaconf import OmegaConf\n",
        "from pathlib import Path\n",
        "\n",
        "# 添加项目路径\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "from datasets.multi_scene_dataset import MultiSceneDataset\n",
        "\n",
        "# 设置设备\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 配置数据集\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 配置数据路径\n",
        "data_cfg = OmegaConf.create({\n",
        "    'data_root': '/path/to/your/data',  # 修改为你的数据路径\n",
        "    'dataset': 'nuscenes',  # 或 'waymo', 'kitti' 等\n",
        "    'start_timestep': 0,\n",
        "    'end_timestep': -1,\n",
        "    'preload_device': 'cpu',\n",
        "    'pixel_source': {\n",
        "        'type': 'datasets.nuscenes.nuscenes_sourceloader.NuScenesPixelSource',\n",
        "        'cameras': [0, 1, 2],\n",
        "        'downscale_when_loading': [3, 3, 3],\n",
        "        'downscale': 1,\n",
        "        'undistort': False,\n",
        "        'test_image_stride': 0,\n",
        "        'load_sky_mask': True,\n",
        "        'load_dynamic_mask': True,\n",
        "        'load_depth_maps': True,\n",
        "        'load_objects': True,\n",
        "        'load_smpl': False,\n",
        "    },\n",
        "    'lidar_source': {},\n",
        "})\n",
        "\n",
        "# 创建数据集实例\n",
        "dataset = MultiSceneDataset(\n",
        "    data_cfg=data_cfg,\n",
        "    train_scene_ids=[0, 1, 2, 3, 4],  # 训练场景ID列表\n",
        "    eval_scene_ids=[5, 6],  # 评估场景ID列表\n",
        "    num_source_keyframes=3,  # 每个批次使用的源关键帧数量\n",
        "    num_target_keyframes=6,  # 每个批次使用的目标关键帧数量\n",
        "    segment_overlap_ratio=0.2,  # 段之间的重叠比例\n",
        "    keyframe_split_config={\n",
        "        'num_splits': 0,  # 0 表示自动确定分割数量\n",
        "        'min_count': 1,\n",
        "        'min_length': 0.0,\n",
        "    },\n",
        "    min_keyframes_per_scene=10,  # 每个场景最少需要的关键帧数\n",
        "    min_keyframes_per_segment=6,  # 每个段最少需要的关键帧数\n",
        "    device=device,\n",
        "    preload_scene_count=3,  # 预加载的场景数量\n",
        "    fixed_segment_aabb=None,  # 可选：固定段的AABB边界框\n",
        ")\n",
        "\n",
        "print(f\"数据集已创建，训练场景数: {len(dataset.train_scene_ids)}, 评估场景数: {len(dataset.eval_scene_ids)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 初始化数据集\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 初始化数据集（可选，会在第一次使用时自动初始化）\n",
        "dataset.initialize()\n",
        "\n",
        "# 获取当前场景ID\n",
        "current_scene_id = dataset.get_current_scene_id()\n",
        "print(f\"当前训练场景: {current_scene_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 获取批次数据\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 方式1: 获取随机批次\n",
        "batch = dataset.sample_random_batch()\n",
        "\n",
        "print(f\"批次信息:\")\n",
        "print(f\"  场景ID: {batch['scene_id'].item()}\")\n",
        "print(f\"  段ID: {batch['segment_id']}\")\n",
        "print(f\"  源关键帧数量: {len(batch['source_keyframes'])}\")\n",
        "print(f\"  目标关键帧数量: {len(batch['target_keyframes'])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 方式2: 获取指定场景和段的批次\n",
        "batch = dataset.get_segment_batch(scene_id=0, segment_id=2)\n",
        "\n",
        "print(f\"指定场景和段的批次:\")\n",
        "print(f\"  场景ID: {batch['scene_id'].item()}\")\n",
        "print(f\"  段ID: {batch['segment_id']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 获取场景信息\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 获取场景信息\n",
        "scene_info = dataset.get_scene(scene_id=0)\n",
        "if scene_info:\n",
        "    print(f\"场景 0 信息:\")\n",
        "    print(f\"  段数量: {len(scene_info['segments'])}\")\n",
        "    print(f\"  总帧数: {scene_info['num_frames']}\")\n",
        "    print(f\"  相机数量: {scene_info['num_cams']}\")\n",
        "    \n",
        "    # 查看第一个段的信息\n",
        "    if len(scene_info['segments']) > 0:\n",
        "        segment = scene_info['segments'][0]\n",
        "        print(f\"\\n第一个段信息:\")\n",
        "        print(f\"  关键帧范围: {segment.get('keyframe_range', 'N/A')}\")\n",
        "        print(f\"  AABB: {segment.get('aabb', 'N/A')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 在训练循环中使用\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 方式1: 使用 sample_random_batch（简单方式）\n",
        "for iteration in range(10):  # 示例：10次迭代\n",
        "    batch = dataset.sample_random_batch()\n",
        "    scene_id = batch['scene_id'].item()\n",
        "    segment_id = batch['segment_id']\n",
        "    \n",
        "    # 使用批次进行训练\n",
        "    # loss = model(batch)\n",
        "    # loss.backward()\n",
        "    # optimizer.step()\n",
        "    \n",
        "    if iteration % 5 == 0:\n",
        "        print(f\"迭代 {iteration}: 场景 {scene_id}, 段 {segment_id}\")\n",
        "    \n",
        "    # 如果场景训练完成，标记并切换到下一个场景\n",
        "    # dataset.mark_scene_completed(scene_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 方式2: 使用调度器（推荐方式，更灵活）\n",
        "scheduler = dataset.create_scheduler(\n",
        "    batches_per_segment=20,  # 每个段生成20个批次\n",
        "    segment_order=\"random\",  # 段顺序：\"random\" 或 \"sequential\"\n",
        "    scene_order=\"random\",  # 场景顺序：\"random\" 或 \"sequential\"\n",
        "    shuffle_segments=True,  # 是否打乱段\n",
        "    preload_next_scene=True,  # 是否预加载下一个场景\n",
        ")\n",
        "\n",
        "try:\n",
        "    for iteration, batch in enumerate(scheduler):\n",
        "        scene_id = batch['scene_id'].item()\n",
        "        segment_id = batch['segment_id']\n",
        "        \n",
        "        # 使用批次进行训练\n",
        "        # loss = model(batch)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        \n",
        "        if iteration % 10 == 0:\n",
        "            print(f\"迭代 {iteration}: 场景 {scene_id}, 段 {segment_id}\")\n",
        "        \n",
        "        # 可以在这里添加训练逻辑\n",
        "        \n",
        "except StopIteration:\n",
        "    print(\"所有批次已处理完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 获取段的关键帧\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 获取指定场景和段的关键帧列表\n",
        "frame_indices = dataset.get_segment_frames(scene_id=0, segment_id=0)\n",
        "print(f\"场景 0, 段 0 的关键帧: {frame_indices[:10]}...\" if len(frame_indices) > 10 else f\"场景 0, 段 0 的关键帧: {frame_indices}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 获取单帧数据\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 获取指定场景、帧和相机的数据\n",
        "frame_data = dataset.get_frame_data(\n",
        "    scene_id=0,\n",
        "    frame_idx=10,\n",
        "    cam_idx=0,\n",
        ")\n",
        "\n",
        "if frame_data:\n",
        "    print(f\"帧数据键: {list(frame_data.keys())}\")\n",
        "    if 'image' in frame_data:\n",
        "        print(f\"图像形状: {frame_data['image'].shape}\")\n",
        "    if 'depth' in frame_data:\n",
        "        print(f\"深度图形状: {frame_data['depth'].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 可视化（可选）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 示例：可视化源图像和目标图像\n",
        "batch = dataset.sample_random_batch()\n",
        "\n",
        "# 获取第一个源关键帧的图像\n",
        "if len(batch['source_keyframes']) > 0:\n",
        "    source_frame = batch['source_keyframes'][0]\n",
        "    source_data = dataset.get_frame_data(\n",
        "        scene_id=batch['scene_id'].item(),\n",
        "        frame_idx=source_frame,\n",
        "        cam_idx=0,\n",
        "    )\n",
        "    \n",
        "    if source_data and 'image' in source_data:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(source_data['image'])\n",
        "        plt.title(f\"源关键帧 {source_frame}\")\n",
        "        plt.axis('off')\n",
        "        \n",
        "        # 获取第一个目标关键帧的图像\n",
        "        if len(batch['target_keyframes']) > 0:\n",
        "            target_frame = batch['target_keyframes'][0]\n",
        "            target_data = dataset.get_frame_data(\n",
        "                scene_id=batch['scene_id'].item(),\n",
        "                frame_idx=target_frame,\n",
        "                cam_idx=0,\n",
        "            )\n",
        "            \n",
        "            if target_data and 'image' in target_data:\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.imshow(target_data['image'])\n",
        "                plt.title(f\"目标关键帧 {target_frame}\")\n",
        "                plt.axis('off')\n",
        "                \n",
        "                plt.tight_layout()\n",
        "                plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 注意事项\n",
        "\n",
        "1. **数据路径配置**：确保 `data_cfg.data_root` 指向正确的数据目录\n",
        "2. **场景ID**：确保 `train_scene_ids` 和 `eval_scene_ids` 中的场景ID在数据集中存在\n",
        "3. **内存管理**：`preload_scene_count` 控制预加载的场景数量，根据可用内存调整\n",
        "4. **线程安全**：数据集支持多线程场景加载，但确保在使用时遵循线程安全的最佳实践\n",
        "5. **批次格式**：返回的批次数据格式符合 EVolSplat 训练要求\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
